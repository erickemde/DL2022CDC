{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Deep Learning Models with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Examples with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Forward NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters \n",
    "input_size = 784\n",
    "hidden_size = 500\n",
    "num_classes = 10\n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.5148\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2282\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2323\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1886\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1029\n",
      "Epoch [1/5], Step [600/600], Loss: 0.2857\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1068\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1272\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1212\n",
      "Epoch [2/5], Step [400/600], Loss: 0.0948\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1152\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0985\n",
      "Epoch [3/5], Step [100/600], Loss: 0.1459\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0655\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0360\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0348\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0367\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0468\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0384\n",
      "Epoch [4/5], Step [200/600], Loss: 0.1231\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0318\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0302\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0866\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0330\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0353\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0346\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0150\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0336\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0674\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0604\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 97.98 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  3.7706, -12.3794,  -3.0856, -10.3720,   6.5720,  -3.1438,   2.4467,\n",
       "          -3.1132,  -5.2714,  -3.7699]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "one_batch = next(iter(test_loader))\n",
    "k = 33\n",
    "one_image = one_batch[0][k]\n",
    "one_label = one_batch[1][k]\n",
    "\n",
    "one_image_npy = one_image.squeeze().numpy()\n",
    "plt.imshow(one_image_npy, cmap='gray')\n",
    "\n",
    "image = one_image.reshape(1,28*28).to(device)\n",
    "label = one_label.to(device)\n",
    "print(one_label)\n",
    "model(image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
